{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc -O ffhq256-1k-validation.zip 'https://www.dropbox.com/scl/fi/pppstbdsf0em6o0qscruc/ffhq256-1k-validation.zip?rlkey=xl7nwv2nxb6yvsirr3wad77hm'\n",
    "!unzip -nq ffhq256-1k-validation.zip -d images\n",
    "!rm ffhq256-1k-validation.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc -O ffhq_10m.pt 'https://www.dropbox.com/scl/fi/pq72vxzxcbygieq5z4gvf/ffhq_10m.pt?rlkey=5sxdj6r4o9f7b7bbp5fxg2f5r' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import random\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from dps.guided_diffusion.unet import create_model\n",
    "from ddrm.functions.svd_replacement import Inpainting,Denoising,Deblurring,SuperResolution,Colorization, GeneralH\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover(y_0, H_funcs, sigma=0,flag = 'Denoising'):\n",
    "    if flag == 'Denoising' or flag == 'Deblurring':\n",
    "        y = y_0.view(1, 3, 256, 256)\n",
    "        y+=torch.randn_like(y)*sigma\n",
    "    elif flag == 'Inpainting':\n",
    "        kept_indices=H_funcs.kept_indices\n",
    "        y_0+=torch.randn_like(y_0)*sigma\n",
    "        y=torch.zeros((1,3,256,256)).to(device)-1\n",
    "\n",
    "        for i in range(len(kept_indices)):\n",
    "            idx = kept_indices[i]\n",
    "            y[0, idx%3, idx//3//256, idx//3%256] = y_0[0, i]\n",
    "        \n",
    "    elif flag == 'Colorization':\n",
    "        y = y_0.view(1, 256, 256)\n",
    "        y=torch.cat([y, y, y], dim=0).unsqueeze(0)\n",
    "        y+=torch.randn_like(y)*sigma\n",
    "\n",
    "    elif 'SuperResolution' in flag:\n",
    "        factor=int(flag[15:])\n",
    "\n",
    "        y = y_0.view(1, 3, 256//factor, 256//factor)\n",
    "        y+=torch.randn_like(y)*sigma\n",
    "        y_large = torch.zeros((1, 3, 256, 256))\n",
    "        for i in range(32):  \n",
    "            for j in range(32):  \n",
    "                y_large[:, :, i*factor:(i+1)*factor, j*factor:(j+1)*factor] = y[:, :, i:i+1, j:j+1]\n",
    "        y = y_large\n",
    "    else : print('flag not recognized')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_config = {'image_size': 256,\n",
    "                'num_channels': 128,\n",
    "                'num_res_blocks': 1,\n",
    "                'channel_mult': '',\n",
    "                'learn_sigma': True,\n",
    "                'class_cond': False,\n",
    "                'use_checkpoint': False,\n",
    "                'attention_resolutions': 16,\n",
    "                'num_heads': 4,\n",
    "                'num_head_channels': 64,\n",
    "                'num_heads_upsample': -1,\n",
    "                'use_scale_shift_norm': True,\n",
    "                'dropout': 0.0,\n",
    "                'resblock_updown': True,\n",
    "                'use_fp16': False,\n",
    "                'use_new_attention_order': False,\n",
    "                'model_path': 'ffhq_10m.pt'}\n",
    "model = create_model(**model_config)\n",
    "model = model.to(device)\n",
    "# use in eval mode:\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pilimg_to_tensor(pil_img):\n",
    "  t = torchvision.transforms.ToTensor()(pil_img)\n",
    "  t = 2*t-1 # [0,1]->[-1,1]\n",
    "  t = t.unsqueeze(0)\n",
    "  t = t.to(device)\n",
    "  return(t)\n",
    "\n",
    "def display_as_pilimg(t):\n",
    "  if t.min()<0:\n",
    "    t = 0.5+0.5*t\n",
    "  t=t.to('cpu')\n",
    "  t = t.squeeze()\n",
    "  t = t.clamp(0.,1.)\n",
    "  pil_img = torchvision.transforms.ToPILImage()(t)\n",
    "  display(pil_img)\n",
    "  return(pil_img)\n",
    "\n",
    "def to_pilimg(t):\n",
    "  if t.min()<0:\n",
    "    t = 0.5+0.5*t\n",
    "  t=t.to('cpu')\n",
    "  t = t.squeeze()\n",
    "  t = t.clamp(0.,1.)\n",
    "  pil_img = torchvision.transforms.ToPILImage()(t)\n",
    "  return(pil_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DPS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPM:\n",
    "  def __init__(self, model=model):\n",
    "    self.num_diffusion_timesteps = 1000\n",
    "    self.reversed_time_steps = np.arange(self.num_diffusion_timesteps)[::-1]\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    self.betas = np.linspace(beta_start, beta_end, self.num_diffusion_timesteps,\n",
    "                              dtype=np.float64)\n",
    "    self.alphas = 1.0 - self.betas\n",
    "    self.alphas_cumprod = np.cumprod(self.alphas, axis=0)\n",
    "    self.alphas_cumprod_prev = np.append(1.0, self.alphas_cumprod[:-1])\n",
    "    self.model = model\n",
    "    self.imgshape = (1,3,256,256)\n",
    "\n",
    "\n",
    "  def get_eps_from_model(self, x, t):\n",
    "    # the model outputs:\n",
    "    # - an estimation of the noise eps (chanels 0 to 2)\n",
    "    # - learnt variances for the posterior  (chanels 3 to 5)\n",
    "    # (see Improved Denoising Diffusion Probabilistic Models\n",
    "    # by Alex Nichol, Prafulla Dhariwal\n",
    "    # for the parameterization)\n",
    "    # We discard the second part of the output for this practice session.\n",
    "    model_output = self.model(x, torch.tensor(t, device=device).unsqueeze(0))\n",
    "    model_output = model_output[:,:3,:,:]\n",
    "    return(model_output)\n",
    "\n",
    "  def predict_xstart_from_eps(self, x, eps, t):\n",
    "    x_start = (\n",
    "        np.sqrt(1.0 / self.alphas_cumprod[t])* x\n",
    "        - np.sqrt(1.0 / self.alphas_cumprod[t] - 1) * eps\n",
    "    )\n",
    "    x_start = x_start.clamp(-1.,1.)\n",
    "    return(x_start)\n",
    "\n",
    "  def sample(self, show_steps=True,skip=10):\n",
    "    with torch.no_grad():  # avoid backprop wrt model parameters\n",
    "      xt = torch.randn(self.imgshape,device=device)  # initialize x_t for t=T\n",
    "      for i, t in enumerate(self.reversed_time_steps[::skip]):\n",
    "        if t > 1:\n",
    "          z = torch.randn(self.imgshape, device=device)\n",
    "        else:\n",
    "          z = torch.zeros(self.imgshape, device=device)\n",
    "\n",
    "        alpha_t = self.alphas[t]\n",
    "        alpha_bar_t = self.alphas_cumprod[t]\n",
    "        sigma_t = np.sqrt(self.betas[t])\n",
    "\n",
    "        eps = self.get_eps_from_model(xt,t)\n",
    "\n",
    "        xt = 1/np.sqrt(alpha_t) * (xt -  (1-alpha_t) / np.sqrt(1-alpha_bar_t) * eps ) + sigma_t * z\n",
    "\n",
    "        xhat = self.predict_xstart_from_eps(xt, eps, t)\n",
    "\n",
    "        if show_steps and t%100==0:\n",
    "          print('Iteration :', t)\n",
    "          pilimg = display_as_pilimg(torch.cat((xt, xhat), dim=3))\n",
    "\n",
    "    return(xt)\n",
    "\n",
    "  def posterior_sampling(self, linear_operator, y, x_true=None, skip=10, show_steps=True, vis_y=None):\n",
    "\n",
    "    # visualization image for the observation y:\n",
    "    if vis_y==None:\n",
    "      vis_y = y\n",
    "\n",
    "    # initialize xt for t=T\n",
    "    x = torch.randn(self.imgshape,device=device)\n",
    "    x.requires_grad = True\n",
    "\n",
    "    reduced_time_steps = self.reversed_time_steps[::skip]\n",
    "    for t in tqdm(reduced_time_steps[1:]):\n",
    "      alpha_t = self.alphas[t]\n",
    "      alpha_bar_t = self.alphas_cumprod[t]\n",
    "      alpha_bar_tm1 = self.alphas_cumprod_prev[t]\n",
    "\n",
    "      beta_t = self.betas[t]\n",
    "      sigma_t = np.sqrt(beta_t)\n",
    "\n",
    "      z = torch.randn(self.imgshape, device=device)\n",
    "\n",
    "      xhat = self.predict_xstart_from_eps(x, self.get_eps_from_model(x,t), t)\n",
    "\n",
    "      x_prime = np.sqrt(alpha_t) * (1-alpha_bar_tm1) / (1-alpha_bar_t) * x\n",
    "      x_prime += np.sqrt(alpha_bar_tm1)*beta_t / (1-alpha_bar_t)*xhat\n",
    "      x_prime += sigma_t*z\n",
    "\n",
    "      df_term = torch.sum((y-linear_operator(xhat))**2)\n",
    "      grad = torch.autograd.grad(df_term, x)[0]\n",
    "      zeta = 0.1 / torch.sqrt(df_term)\n",
    "\n",
    "      x = x_prime - zeta * grad\n",
    "\n",
    "      if show_steps and (t)%100==0:\n",
    "        print('Iteration :', t)\n",
    "        pilimg = display_as_pilimg(torch.cat((x, xhat, y, x_true), dim=3))\n",
    "\n",
    "    return(xhat)\n",
    "\n",
    "\n",
    "ddpm = DDPM()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask DPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 256\n",
    "w = 256\n",
    "hcrop, wcrop = h//2, w//2\n",
    "corner_top, corner_left = h//4, int(0.45*w)\n",
    "mask = torch.ones((1,3,256, 256), device=device)\n",
    "mask[:,:,corner_top:corner_top+hcrop,corner_left:corner_left+wcrop] = 0\n",
    "\n",
    "\n",
    "# Redimensionner le masque pour correspondre à la forme de l'image (1, 3, h, w)\n",
    "\n",
    "def linear_operator(x):\n",
    "  x = x*mask-(1-mask)\n",
    "  return(x)\n",
    "\n",
    "idx = 12\n",
    "x_true_pil = Image.open('images/ffhq256-1k-validation/'+str(idx).zfill(5)+'.png')\n",
    "x_true = pilimg_to_tensor(x_true_pil)\n",
    "print(x_true.device)\n",
    "print(\"original image\", str(idx).zfill(5)+'.png')\n",
    "display_as_pilimg(x_true)\n",
    "\n",
    "sigma_noise = 0\n",
    "\n",
    "y = linear_operator(x_true.clone()) + sigma_noise * mask * torch.randn_like(x_true)\n",
    "print(\"noisy measurement\")\n",
    "display_as_pilimg(y);\n",
    "\n",
    "print(y.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDRM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddrm.functions.denoising import efficient_generalized_steps\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torchvision.utils as tvu\n",
    "import os\n",
    "\n",
    "class DDRM:\n",
    "    def __init__(self, model):\n",
    "        self.num_timesteps = 1000\n",
    "        self.reversed_time_steps = np.arange(self.num_timesteps)[::-1]\n",
    "        beta_start = 0.0001\n",
    "        beta_end = 0.02\n",
    "        betas = np.linspace(\n",
    "            beta_start, beta_end, self.num_timesteps, dtype=np.float64\n",
    "        )\n",
    "        betas = self.betas = torch.from_numpy(betas).float().to(device)\n",
    "        self.num_timesteps = betas.shape[0]\n",
    "\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cumprod = alphas.cumprod(dim=0)\n",
    "        alphas_cumprod_prev = torch.cat(\n",
    "            [torch.ones(1).to(device), alphas_cumprod[:-1]], dim=0\n",
    "        )\n",
    "        self.alphas_cumprod_prev = alphas_cumprod_prev\n",
    "        self.model = model\n",
    "        self.imgshape = (1,3,256,256)\n",
    "\n",
    "\n",
    "    def compute_alpha(self,beta, t):\n",
    "        beta = torch.cat([torch.zeros(1).to(beta.device), beta], dim=0)\n",
    "        a = (1 - beta).cumprod(dim=0).index_select(0, t + 1).view(-1, 1, 1, 1)\n",
    "        return a\n",
    "\n",
    "    def efficient_generalized_steps(self,x, seq, model, b, H_funcs, y_0, sigma_0, etaB, etaA, etaC, cls_fn=None, classes=None):\n",
    "        with torch.no_grad():\n",
    "            #setup vectors used in the algorithm\n",
    "            singulars = H_funcs.singulars()\n",
    "            Sigma = torch.zeros(x.shape[1]*x.shape[2]*x.shape[3], device=x.device)\n",
    "            Sigma[:singulars.shape[0]] = singulars\n",
    "            U_t_y = H_funcs.Ut(y_0)\n",
    "            Sig_inv_U_t_y = U_t_y / singulars[:U_t_y.shape[-1]]\n",
    "\n",
    "            #initialize x_T as given in the paper\n",
    "            largest_alphas = self.compute_alpha(b, (torch.ones(x.size(0)) * seq[-1]).to(x.device).long())\n",
    "            largest_sigmas = (1 - largest_alphas).sqrt() / largest_alphas.sqrt()\n",
    "            large_singulars_index = torch.where(singulars * largest_sigmas[0, 0, 0, 0] > sigma_0)\n",
    "            inv_singulars_and_zero = torch.zeros(x.shape[1] * x.shape[2] * x.shape[3]).to(singulars.device)\n",
    "            inv_singulars_and_zero[large_singulars_index] = sigma_0 / singulars[large_singulars_index]\n",
    "            inv_singulars_and_zero = inv_singulars_and_zero.view(1, -1)     \n",
    "\n",
    "            # implement p(x_T | x_0, y) as given in the paper\n",
    "            # if eigenvalue is too small, we just treat it as zero (only for init) \n",
    "            init_y = torch.zeros(x.shape[0], x.shape[1] * x.shape[2] * x.shape[3]).to(x.device)\n",
    "            init_y[:, large_singulars_index[0]] = U_t_y[:, large_singulars_index[0]] / singulars[large_singulars_index].view(1, -1)\n",
    "            init_y = init_y.view(*x.size())\n",
    "            remaining_s = largest_sigmas.view(-1, 1) ** 2 - inv_singulars_and_zero ** 2\n",
    "            remaining_s = remaining_s.view(x.shape[0], x.shape[1], x.shape[2], x.shape[3]).clamp_min(0.0).sqrt()\n",
    "            init_y = init_y + remaining_s * x\n",
    "            init_y = init_y / largest_sigmas\n",
    "            \n",
    "            #setup iteration variables\n",
    "            x = H_funcs.V(init_y.view(x.size(0), -1)).view(*x.size())\n",
    "            n = x.size(0)\n",
    "            seq_next = [-1] + list(seq[:-1])\n",
    "            x0_preds = []\n",
    "            xs = [x]\n",
    "\n",
    "            #iterate over the timesteps\n",
    "            for i, j in tqdm(zip(reversed(seq), reversed(seq_next))):\n",
    "                t = (torch.ones(n) * i).to(x.device)\n",
    "                next_t = (torch.ones(n) * j).to(x.device)\n",
    "                at = self.compute_alpha(b, t.long())\n",
    "                at_next = self.compute_alpha(b, next_t.long())\n",
    "                xt = xs[-1].to('cuda')\n",
    "                if cls_fn == None:\n",
    "                    et = model(xt, t)\n",
    "                else:\n",
    "                    et = model(xt, t, classes)\n",
    "                    et = et[:, :3]\n",
    "                    et = et - (1 - at).sqrt()[0,0,0,0] * cls_fn(x,t,classes)\n",
    "                \n",
    "                if et.size(1) == 6:\n",
    "                    et = et[:, :3]\n",
    "                \n",
    "                x0_t = (xt - et * (1 - at).sqrt()) / at.sqrt()\n",
    "\n",
    "                #variational inference conditioned on y\n",
    "                sigma = (1 - at).sqrt()[0, 0, 0, 0] / at.sqrt()[0, 0, 0, 0]\n",
    "                sigma_next = (1 - at_next).sqrt()[0, 0, 0, 0] / at_next.sqrt()[0, 0, 0, 0]\n",
    "                xt_mod = xt / at.sqrt()[0, 0, 0, 0]\n",
    "                V_t_x = H_funcs.Vt(xt_mod)\n",
    "                SVt_x = (V_t_x * Sigma)[:, :U_t_y.shape[1]]\n",
    "                V_t_x0 = H_funcs.Vt(x0_t)\n",
    "                SVt_x0 = (V_t_x0 * Sigma)[:, :U_t_y.shape[1]]\n",
    "\n",
    "                falses = torch.zeros(V_t_x0.shape[1] - singulars.shape[0], dtype=torch.bool, device=xt.device)\n",
    "                cond_before_lite = singulars * sigma_next > sigma_0\n",
    "                cond_after_lite = singulars * sigma_next < sigma_0\n",
    "                cond_before = torch.hstack((cond_before_lite, falses))\n",
    "                cond_after = torch.hstack((cond_after_lite, falses))\n",
    "\n",
    "                std_nextC = sigma_next * etaC\n",
    "                sigma_tilde_nextC = torch.sqrt(sigma_next ** 2 - std_nextC ** 2)\n",
    "\n",
    "                std_nextA = sigma_next * etaA\n",
    "                sigma_tilde_nextA = torch.sqrt(sigma_next**2 - std_nextA**2)\n",
    "                \n",
    "                diff_sigma_t_nextB = torch.sqrt(sigma_next ** 2 - sigma_0 ** 2 / singulars[cond_before_lite] ** 2 * (etaB ** 2))\n",
    "\n",
    "                #missing pixels\n",
    "                Vt_xt_mod_next = V_t_x0 + sigma_tilde_nextC * H_funcs.Vt(et) + std_nextC * torch.randn_like(V_t_x0)\n",
    "\n",
    "                #less noisy than y (after)\n",
    "                Vt_xt_mod_next[:, cond_after] = \\\n",
    "                    V_t_x0[:, cond_after] + sigma_tilde_nextA * ((U_t_y - SVt_x0) / sigma_0)[:, cond_after_lite] + std_nextA * torch.randn_like(V_t_x0[:, cond_after])\n",
    "                \n",
    "                #noisier than y (before)\n",
    "                Vt_xt_mod_next[:, cond_before] = \\\n",
    "                    (Sig_inv_U_t_y[:, cond_before_lite] * etaB + (1 - etaB) * V_t_x0[:, cond_before] + diff_sigma_t_nextB * torch.randn_like(U_t_y)[:, cond_before_lite])\n",
    "\n",
    "                #aggregate all 3 cases and give next prediction\n",
    "                xt_mod_next = H_funcs.V(Vt_xt_mod_next)\n",
    "                xt_next = (at_next.sqrt()[0, 0, 0, 0] * xt_mod_next).view(*x.shape)\n",
    "\n",
    "                x0_preds.append(x0_t.to('cpu'))\n",
    "                xs.append(xt_next.to('cpu'))\n",
    "\n",
    "\n",
    "        return xs, x0_preds\n",
    "\n",
    "    def sample_image(self, x, model, H_funcs, y_0, sigma_0, eta, etaB, skip=1, last=True, cls_fn=None, classes=None):\n",
    "            seq = range(0, self.num_timesteps, skip)\n",
    "            \n",
    "            x = self.efficient_generalized_steps(x, seq, model, self.betas, H_funcs, y_0, sigma_0, \\\n",
    "                etaB=etaB, etaA=eta, etaC=eta, cls_fn=cls_fn, classes=classes)\n",
    "            if last:\n",
    "                x = x[0][-1]\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochasticity Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=mask.squeeze()[0].flatten()\n",
    "missing_r = torch.nonzero(mask == 0).long().reshape(-1)*3\n",
    "missing_g = missing_r + 1\n",
    "missing_b = missing_g + 1\n",
    "missing1 = torch.cat([missing_r, missing_g, missing_b], dim=0)\n",
    "H_funcs_inp = Inpainting(3, 256, missing1, device)\n",
    "missing_r = torch.randperm(256**2)[:256**2 // 2].to(device).long() * 3\n",
    "missing_g = missing_r + 1\n",
    "missing_b = missing_g + 1\n",
    "missing = torch.cat([missing_r, missing_g, missing_b], dim=0)\n",
    "H_funcs_inp_random = Inpainting(3, 256, missing,device)\n",
    "sigma = 10\n",
    "pdf = lambda x: torch.exp(torch.Tensor([-0.5 * (x/sigma)**2]))\n",
    "kernel = torch.Tensor([pdf(-2), pdf(-1), pdf(0), pdf(1), pdf(2)]).to(device)\n",
    "H_funcs_gaussian_blur = Deblurring(kernel / kernel.sum(),3, 256, device)\n",
    "H_funcs_color = Colorization(256, device)\n",
    "H_funcs_SR8 = SuperResolution(3, 256, 8,device)\n",
    "H_funcs_SR16 = SuperResolution(3, 256, 16,device)\n",
    "H_funcs_denoising = Denoising(3, 256, device)\n",
    "list_H_funcs = [H_funcs_inp,H_funcs_inp_random, H_funcs_gaussian_blur, H_funcs_SR8, H_funcs_SR16]\n",
    "list_H_names= ['Inpainting','Inpainting', 'Deblurring', 'SuperResolution8', 'SuperResolution16']\n",
    "list_x_true=[pilimg_to_tensor(Image.open('images/ffhq256-1k-validation/'+str(idx).zfill(5)+'.png')) for idx in [12,200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddrm=DDRM(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def evaluate_stochasticity(list_x_true, list_H, list_H_names, model, sigma_0, eta, etaB):\n",
    "    num_transforms = len(list_H)\n",
    "    num_img = len(list_x_true)\n",
    "    num_samples = 5   \n",
    "    num_columns = 4 + num_samples  # pour chaque transformation\n",
    "\n",
    "     \n",
    "    fig, axs = plt.subplots(num_img * num_transforms, num_columns, figsize=(2 * num_columns, 2 * num_img * num_transforms))\n",
    "\n",
    "   \n",
    "    if num_img * num_transforms == 1:\n",
    "        axs = np.array([[axs]])\n",
    "\n",
    "    for i, (H_func, H_name) in enumerate(zip(list_H, list_H_names)):\n",
    "        for j, x_true in enumerate(list_x_true):\n",
    "            \n",
    "            current_row = i * num_img + j\n",
    "\n",
    "            # Afficher l'image originale\n",
    "            axs[current_row, 0].imshow(to_pilimg(x_true.squeeze()))\n",
    "            axs[current_row, 0].axis('off')\n",
    "            if j == 0 and i==0:\n",
    "                axs[current_row, 0].set_title('Original')\n",
    "\n",
    "            # Générer et afficher l'image dégradée\n",
    "            y_0 = H_func.H(x_true)\n",
    "            y = recover(y_0, H_func, sigma_0, H_name)  # Supposons que cette fonction existe\n",
    "            y_0+=torch.randn_like(y_0)*sigma_0\n",
    "            axs[current_row, 1].imshow(to_pilimg(y.squeeze()))\n",
    "            axs[current_row, 1].axis('off')\n",
    "            if j == 0:\n",
    "                axs[current_row, 1].set_title(H_name)\n",
    "\n",
    "            # Générer les images reconstruites (simulé ici par des images aléatoires)\n",
    "            reconstructions = []\n",
    "            for k in range(num_samples):\n",
    "                x_reconstructed = ddrm.sample_image(x_true, model, H_func, y_0, sigma_0, eta, etaB, skip=10, last=True)\n",
    "                reconstructions.append(to_pilimg(x_reconstructed.squeeze().clamp(-1, 1)))\n",
    "\n",
    "            # Convert to PIL images and display\n",
    "            np_images = [np.array(pil_img) for pil_img in reconstructions]\n",
    "\n",
    "            # Compute mean and standard deviation images\n",
    "            stacked_images = np.stack(np_images, axis=0)\n",
    "            mean_image = np.mean(stacked_images, axis=0).astype(np.uint8)\n",
    "            std_dev = np.std(stacked_images, axis=0)\n",
    "            scaled_std_dev = np.clip(std_dev * 4, 0, 255).astype(np.uint8)  # Scale std deviation for visibility\n",
    "\n",
    "            # Afficher la moyenne et l'écart-type des reconstructions (simulé ici)\n",
    "            # Vous devez calculer ces images à partir de vos données réelles\n",
    "            axs[current_row, 7].imshow(mean_image)  # Placeholder pour l'image moyenne\n",
    "            axs[current_row, 7].axis('off')\n",
    "            if j == 0 and i==0:\n",
    "                axs[current_row, 7].set_title('Mean')\n",
    "\n",
    "            axs[current_row, 8].imshow(scaled_std_dev)  # Placeholder pour l'image d'écart-type\n",
    "            axs[current_row, 8].axis('off')\n",
    "            if j == 0 and i==0:\n",
    "                axs[current_row, 8].set_title('Std (x4)')\n",
    "\n",
    "            # Afficher les échantillons de reconstruction\n",
    "            for k, rec_img in enumerate(random.sample(np_images, 5)):\n",
    "                axs[current_row, 2+k].imshow(rec_img)  # Placeholder pour les échantillons de reconstruction\n",
    "                axs[current_row, 2+k].axis('off')\n",
    "                if j == 0 and k == 0 and i==0:\n",
    "                    axs[current_row, 4+k].set_title('Generated samples', loc='center')\n",
    "\n",
    "            # Si c'est la première ligne d'une nouvelle transformation, ajouter le nom de la transformation sur l'axe des y\n",
    "            if j == 0:\n",
    "                axs[current_row, 0].set_ylabel(H_name, rotation=1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_stochasticity(list_x_true, list_H_funcs, list_H_names, model, 0.3, 0.85, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance comparison and NFE influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import torch\n",
    "_ = torch.manual_seed(123)\n",
    "from torchmetrics.image.kid import KernelInceptionDistance\n",
    "kid = KernelInceptionDistance(subset_size=50)\n",
    "\n",
    "def evaluate_metrics_ddrm(H_func, H_name, list_index, model, sigma_0, eta, etaB, skip,sigmay):\n",
    "    list_psnr = []\n",
    "    list_x_reconstructed = []\n",
    "    list_x_true = []\n",
    "    list_y_0 = []\n",
    "    list_ssim = []\n",
    "    list_runtime = []  # List to store runtimes for x_reconstructed computations\n",
    "\n",
    "    for idx in list_index:\n",
    "        x_true_pil = Image.open('images/ffhq256-1k-validation/' + str(idx).zfill(5) + '.png')\n",
    "        x_true = pilimg_to_tensor(x_true_pil)\n",
    "        y_0 = H_func.H(x_true)\n",
    "        y_0+=sigmay*torch.randn_like(y_0)\n",
    "        list_y_0.append(y_0)\n",
    "        list_x_true.append(x_true)\n",
    "\n",
    "        # Start measuring time\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Generate x_reconstructed\n",
    "        x_reconstructed = ddrm.sample_image(x_true, model, H_func, y_0, sigma_0, eta, etaB, skip, last=True)\n",
    "        \n",
    "        # Stop measuring time\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Compute runtime and store it\n",
    "        runtime = end_time - start_time\n",
    "        list_runtime.append(runtime)\n",
    "\n",
    "        list_x_reconstructed.append(x_reconstructed)\n",
    "\n",
    "        # Ensure images are on CPU, detached from computation graph, and in NumPy format\n",
    "        x_true_np = x_true.squeeze().cpu().detach().numpy()\n",
    "        x_reconstructed_np = x_reconstructed.squeeze().cpu().detach().numpy()\n",
    "        \n",
    "        # Transpose the images from (C, H, W) to (H, W, C) for skimage computation\n",
    "        x_true_np = np.transpose(x_true_np, (1, 2, 0))\n",
    "        x_reconstructed_np = np.transpose(x_reconstructed_np, (1, 2, 0))\n",
    "        # Calculate PSNR and SSIM\n",
    "        psnr_val = psnr(x_true_np, x_reconstructed_np)  # Assuming mypsnr handles the data correctly\n",
    "        ssim_val = ssim(x_true_np, x_reconstructed_np, data_range=2, multichannel=True,channel_axis=2)\n",
    "        \n",
    "        \n",
    "        list_psnr.append(psnr_val)\n",
    "        list_ssim.append(ssim_val)\n",
    "\n",
    "    return list_psnr, list_x_reconstructed, list_x_true, list_y_0, list_ssim, list_runtime\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_metrics_ddpm(linear_operator,list_index, skip,sigmay):\n",
    "    list_psnr = []\n",
    "    list_x_reconstructed = []\n",
    "    list_x_true = []\n",
    "    list_y_0 = []\n",
    "    list_ssim = []\n",
    "    list_runtime = []  # List to store runtimes for x_reconstructed computations\n",
    "\n",
    "    for idx in list_index:\n",
    "        x_true_pil = Image.open('images/ffhq256-1k-validation/' + str(idx).zfill(5) + '.png')\n",
    "        x_true = pilimg_to_tensor(x_true_pil)\n",
    "        \n",
    "        list_x_true.append(x_true)\n",
    "\n",
    "        # Start measuring time\n",
    "        start_time = time.time()\n",
    "        y=linear_operator(x_true+sigmay*torch.randn_like(x_true))\n",
    "        list_y_0.append(y)\n",
    "        # Generate x_reconstructed\n",
    "        x_reconstructed = ddpm.posterior_sampling(linear_operator, y, x_true,skip, show_steps=False, vis_y=y)\n",
    "        \n",
    "        # Stop measuring time\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Compute runtime and store it\n",
    "        runtime = end_time - start_time\n",
    "        list_runtime.append(runtime)\n",
    "\n",
    "        list_x_reconstructed.append(x_reconstructed)\n",
    "\n",
    "        # Ensure images are on CPU, detached from computation graph, and in NumPy format\n",
    "        x_true_np = x_true.squeeze().cpu().detach().numpy()\n",
    "        x_reconstructed_np = x_reconstructed.squeeze().cpu().detach().numpy()\n",
    "        \n",
    "        # Transpose the images from (C, H, W) to (H, W, C) for skimage computation\n",
    "        x_true_np = np.transpose(x_true_np, (1, 2, 0))\n",
    "        x_reconstructed_np = np.transpose(x_reconstructed_np, (1, 2, 0))\n",
    "        # Calculate PSNR and SSIM\n",
    "        psnr_val = psnr(x_true_np, x_reconstructed_np)  # Assuming mypsnr handles the data correctly\n",
    "\n",
    "        ssim_val = ssim(x_true_np, x_reconstructed_np, data_range=2, multichannel=True,channel_axis=2)\n",
    "        \n",
    "        \n",
    "        list_psnr.append(psnr_val)\n",
    "        list_ssim.append(ssim_val)\n",
    "\n",
    "    return list_psnr, list_x_reconstructed, list_x_true, list_y_0, list_ssim, list_runtime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_metrics_ddpm(linear_operator,idx , skip,sigma_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Assuming H_funcs_inp and model are defined\n",
    "# Assuming pilimg_to_tensor and other necessary functions are imported\n",
    "\n",
    "# Initialize lists for DDRM metrics\n",
    "list_avg_psnr_ddrm = []\n",
    "list_avg_ssim_ddrm = []\n",
    "list_std_psnr_ddrm = []\n",
    "list_std_ssim_ddrm = []\n",
    "list_avg_time_ddrm = []\n",
    "list_std_time_ddrm = []\n",
    "\n",
    "# Initialize lists for DDPM metrics\n",
    "list_avg_psnr_ddpm = []\n",
    "list_avg_ssim_ddpm = []\n",
    "list_std_psnr_ddpm = []\n",
    "list_std_ssim_ddpm = []\n",
    "list_avg_time_ddpm = []\n",
    "list_std_time_ddpm = []\n",
    "\n",
    "idx = random.sample(range(1000), 10)\n",
    "sigma_y = 0\n",
    "list_skip = [1,2,5,10,20,50]\n",
    "\n",
    "for skip in list_skip:\n",
    "    print(f\"Skip: {skip}\")\n",
    "    # DDRM Evaluation\n",
    "    list_psnr_ddrm, list_x_reconstructed_ddrm, list_x_true_ddrm, list_y_0_ddrm, list_ssim_ddrm, list_runtime_ddrm = evaluate_metrics_ddrm(\n",
    "        H_funcs_inp, 'Inpainting', idx, model, 0.05, 0.85, 1, skip, sigma_y)\n",
    "    list_avg_psnr_ddrm.append(np.mean(list_psnr_ddrm))\n",
    "    list_avg_ssim_ddrm.append(np.mean(list_ssim_ddrm))\n",
    "    list_std_psnr_ddrm.append(np.std(list_psnr_ddrm))\n",
    "    list_std_ssim_ddrm.append(np.std(list_ssim_ddrm))\n",
    "    list_avg_time_ddrm.append(np.mean(list_runtime_ddrm))\n",
    "    list_std_time_ddrm.append(np.std(list_runtime_ddrm))\n",
    "\n",
    "    # DDPM Evaluation\n",
    "    # Replace `evaluate_metrics_ddpm` with your DDPM evaluation function if necessary\n",
    "    list_psnr_ddpm, list_x_reconstructed_ddpm, list_x_true_ddpm, list_y_0_ddpm, list_ssim_ddpm, list_runtime_ddpm = evaluate_metrics_ddpm(linear_operator,idx , skip,sigma_y)\n",
    "    list_avg_psnr_ddpm.append(np.mean(list_psnr_ddpm))\n",
    "    list_avg_ssim_ddpm.append(np.mean(list_ssim_ddpm))\n",
    "    list_std_psnr_ddpm.append(np.std(list_psnr_ddpm))\n",
    "    list_std_ssim_ddpm.append(np.std(list_ssim_ddpm))\n",
    "    list_avg_time_ddpm.append(np.mean(list_runtime_ddpm))\n",
    "    list_std_time_ddpm.append(np.std(list_runtime_ddpm))\n",
    "# Here you can print or further process the collected metrics for both DDRM and DDPM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(1000//np.array(list_skip[:-1]),list_avg_psnr_ddrm[:-1],label='DDRM',marker='x')\n",
    "plt.plot(1000//np.array(list_skip[:-1]),list_avg_psnr_ddpm[:-1],label='DPS',marker='x')\n",
    "plt.xlabel('Number of NFE [50,100,200,500,1000]')\n",
    "plt.ylabel('Avg. PSNR (10 samples)')\n",
    "plt.title('Average PSNR vs. Number of NFE, Square Inpainting ($\\sigma=0$)')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('psnr0square.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(1000//np.array(list_skip[:-1]),list_avg_ssim_ddrm[:-1],label='DDRM',marker='x')\n",
    "plt.plot(1000//np.array(list_skip[:-1]),list_avg_ssim_ddpm[:-1],label='DPS',marker='x')\n",
    "plt.xlabel('Number of NFE [50,100,200,500,1000]')\n",
    "plt.ylabel('Avg. SSIM (10 samples)')\n",
    "plt.title('Average PSNR vs. Number of NFE, Square Inpainting ($\\sigma=0$)')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('ssim0square.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(list_avg_psnr_ddrm)\n",
    "print(list_avg_ssim_ddrm)\n",
    "print(list_std_psnr_ddrm)\n",
    "print(list_std_ssim_ddrm)\n",
    "print(list_avg_time_ddrm)\n",
    "print(list_std_time_ddrm)\n",
    "\n",
    "# Initialize lists for DDPM metrics\n",
    "print(list_avg_psnr_ddpm)\n",
    "print(list_avg_ssim_ddpm)\n",
    "print(list_std_psnr_ddpm)\n",
    "print(list_std_ssim_ddpm)\n",
    "print(list_avg_time_ddpm)\n",
    "print(list_std_time_ddpm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
